seed_everything: 42
model:
  pretrained_model: "google/byt5-small"
  from_flax: false
  use_pretraining: true
  learning_rate: 3e-5
  target_max_length: 5
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_eps: 1e-8
  adam_weight_decay: 0.0
  output_dir: "./output/byt5-mnli/"
data:
  tokenizer_name: "google/byt5-small"
  train_dataset: "glue"
  train_subdataset: mnli
  validation_set: validation_matched
  batch_size: 2
  max_length: 1024
  target_max_length: 5
  xlang_dataset_name: "glue"
  xlang_subdataset_name: mnli
  xlang_validation_set: validation_matched
  transliteration: true
  min_chars: 3
  max_chars: 7
  max_training_examples: null
  max_validation_examples: 5000
trainer:
  gpus: 1
  max_epochs: 5
  val_check_interval: 0.1
  gradient_clip_val: 1.0
  accumulate_grad_batches: 8
  precision: 32
  default_root_dir: "./checkpoints"
  enable_checkpointing: true
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint
      init_args:
        dirpath: ./output/byt5-mnli/checkpoints
        every_n_train_steps: 50000 # Opcional, por padrão ele salva no final da época
  logger:
    class_path: pytorch_lightning.loggers.NeptuneLogger
    init_args:
      log_model_checkpoints: false
